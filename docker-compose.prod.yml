services:
  # Main service for running the PostgreSQL scheduler jobs
  jobs:
    # Name and tag of image the Dockerfile creates
    image: mccarthysean/ijack:postgresql_scheduler_final
    # this will signal that the connection is alive after 200 seconds,
    # which is less than the time it takes to drop the connection (300 seconds?), thus preventing it from being dropped.
    # https://stackoverflow.com/questions/56289874/postgres-closes-connection-during-query-after-a-few-hundred-seconds-when-using-p
    # https://github.com/moby/moby/issues/31208#issuecomment-303905737
    sysctls:
      - net.ipv4.tcp_keepalive_time=200
      - net.ipv4.tcp_keepalive_intvl=30
      - net.ipv4.tcp_keepalive_probes=10
    env_file: .env
    networks:
      - traefik-public
    deploy:
      # Either global (exactly one container per physical node) or
      # replicated (a specified number of containers). The default is replicated
      mode: replicated
      # For stateless applications using "replicated" mode,
      # the total number of replicas to create
      replicas: 1
      # Update configuration with automatic rollback on failure
      update_config:
        # Update one container at a time
        parallelism: 1
        # Wait 30s between updates
        delay: 30s
        # Rollback if update fails
        failure_action: rollback
        # Monitor for 2 minutes before considering update successful
        monitor: 2m
        # If more than 50% of tasks fail, trigger rollback
        max_failure_ratio: 0.5
        # Order: stop old task before starting new one (safer for stateful apps)
        order: stop-first
      # Rollback configuration
      rollback_config:
        # Rollback one container at a time
        parallelism: 1
        # Wait 10s between rollback steps
        delay: 10s
        # Pause rollback on failure (manual intervention needed)
        failure_action: pause
        # Monitor for 1 minute during rollback
        monitor: 1m
        # Order: stop new (failed) task before starting old one
        order: stop-first
      # Restart policy: restart on failure, with exponential backoff
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      placement:
        constraints:
          - node.platform.os == linux
          # We need this to monitor the main AWS EC2 instance's disk space
          - node.role == manager
          # "Backup server" (which is a manager as well)
          # - node.id == n6ft9t731ty64r28muac1540j
      resources:
        limits:
          # The container can use up to X% of a single CPU
          cpus: '0.25'
          # # The container can use up to X amount of memory (might need lots when reading from the database)
          # memory: 2048M
      # labels:
      #   # Enable logging to Grafana Loki with Promtail
      #   logging: promtail
      #   logging_jobname: postgresql_scheduler
    # Enhanced health check that verifies Python can import modules
    healthcheck:
      test: [
        "CMD-SHELL",
        "/app/.venv/bin/python -c 'import pytz, pandas, psycopg2; import project.logger_config' || exit 1"
      ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    # volumes:
    #   - type: volume
    #     source: postgresql_scheduler_logs_prod
    #     target: /app/logs
    #     read_only: false
    #     volume:
    #       nocopy: true
    command: ["/app/.venv/bin/python", "/app/scheduler_jobs.py"]

  # Second service for globally monitoring the EC2 instances' disk space
  monitor:
    # Name and tag of image the Dockerfile creates
    image: mccarthysean/ijack:postgresql_scheduler_final
    # this will signal that the connection is alive after 200 seconds,
    # which is less than the time it takes to drop the connection (300 seconds?), thus preventing it from being dropped.
    # https://stackoverflow.com/questions/56289874/postgres-closes-connection-during-query-after-a-few-hundred-seconds-when-using-p
    # https://github.com/moby/moby/issues/31208#issuecomment-303905737
    sysctls:
      - net.ipv4.tcp_keepalive_time=200
      - net.ipv4.tcp_keepalive_intvl=30
      - net.ipv4.tcp_keepalive_probes=10
    env_file: .env
    networks:
      - traefik-public
    deploy:
      # Either global (exactly one container per physical node) or
      # replicated (a specified number of containers). The default is replicated
      mode: global
      # For stateless applications using "replicated" mode,
      # the total number of replicas to create
      # replicas: 1
      # Don't use a restart policy. Let Docker Swarm handle it.
      restart_policy:
        # condition: on-failure
        condition: any
      placement: 
        constraints:
          - node.platform.os == linux
      resources:
        limits:
          # The container can use up to X% of a single CPU
          cpus: '0.25'
          # # The container can use up to X amount of memory (might need lots when reading from the database)
          # memory: 2048M
      # labels:
      #   # Enable logging to Grafana Loki with Promtail
      #   logging: promtail
      #   logging_jobname: postgresql_scheduler
    healthcheck:
      test: [ "CMD", "ping", "-c", "1", "google.com" ]
      interval: 1m
      timeout: 5m
      retries: 3
      start_period: 30s
    # volumes:
    #   - type: volume
    #     source: postgresql_scheduler_monitor_logs_prod
    #     target: /app/logs
    #     read_only: false
    #     volume:
    #       nocopy: true
    command: ["/app/.venv/bin/python", "/app/scheduler_monitor.py"]

networks:
  # Use the previously created public network "traefik-public", shared with other services
  traefik-public:
    external: true

# volumes:
#   postgresql_scheduler_logs_prod:
#   postgresql_scheduler_monitor_logs_prod:
